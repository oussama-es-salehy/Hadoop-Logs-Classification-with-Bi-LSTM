{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5TAratXsot_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import json\n",
        "\n",
        "def safe_train_test_split(X, y, test_size=0.5, random_state=None, stratify_labels=None):\n",
        "    \"\"\"Performs train_test_split, falling back to non-stratified if stratification fails due to minority classes.\"\"\"\n",
        "    if stratify_labels is None:\n",
        "        return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    try:\n",
        "        # Attempt stratified split\n",
        "        return train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=stratify_labels)\n",
        "    except ValueError as e:\n",
        "        if \"The least populated class in y has only 1 member\" in str(e):\n",
        "            print(f\"Warning: Stratified split failed due to minority class(es). Falling back to non-stratified split for this step.\")\n",
        "            # Fallback to non-stratified split\n",
        "            return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "        else:\n",
        "            # Re-raise other ValueErrors\n",
        "            raise e"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Config\n",
        "# ---------------------------\n",
        "DATA_PATH = \"Hadoop_2k.log_structured.csv\"  # <-- change si nécessaire\n",
        "MODEL_DIR = \"saved_model\"\n",
        "TOKENIZER_PATH = os.path.join(MODEL_DIR, \"tokenizer.json\")\n",
        "MODEL_PATH = os.path.join(MODEL_DIR, \"lstm_Hadoop.h5\")\n",
        "MAX_VOCAB = 20000\n",
        "MAX_LEN = 120\n",
        "EMBEDDING_DIM = 128\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10\n",
        "RANDOM_STATE = 42\n"
      ],
      "metadata": {
        "id": "nlba8qtps6pQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilitaires\n",
        "# ---------------------------\n",
        "def load_data(path=DATA_PATH):\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"Le fichier {path} est introuvable. Placez le CSV dans le dossier courant.\")\n",
        "    df = pd.read_csv(path, low_memory=False)\n",
        "    # Assure existence de colonnes\n",
        "    if 'Content' not in df.columns or 'Level' not in df.columns:\n",
        "        raise ValueError(\"Le fichier doit contenir au moins les colonnes 'Content' et 'Level'.\")\n",
        "    df = df[['Content', 'Level']].dropna().reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "def clean_text(text):\n",
        "    # nettoyage léger, conserve les mots techniques\n",
        "    text = str(text)\n",
        "    text = text.lower()\n",
        "    # remplacer chemins et nombres par token\n",
        "    text = re.sub(r'\\/\\S+', ' ', text)\n",
        "    text = re.sub(r'\\d+([:._-]?\\d+)*', ' ', text)\n",
        "    # garder lettres, underscore et espaces\n",
        "    text = re.sub(r'[^a-z0-9_ ]+', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text"
      ],
      "metadata": {
        "id": "VM-EJhkqtCHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Préparation dataset\n",
        "# ---------------------------\n",
        "print(\"Loading data...\")\n",
        "df = load_data(DATA_PATH)\n",
        "print(f\"Loaded {len(df)} lines.\")\n",
        "\n",
        "print(\"Cleaning content...\")\n",
        "df['clean'] = df['Content'].apply(clean_text)\n",
        "\n",
        "# labels\n",
        "print(\"Encoding labels...\")\n",
        "le = LabelEncoder()\n",
        "df['label_enc'] = le.fit_transform(df['Level'])\n",
        "label_map = {int(i): lab for i, lab in enumerate(le.classes_)}\n",
        "print(\"Label mapping:\", label_map)\n",
        "\n",
        "# split\n",
        "X = df['clean'].values\n",
        "y = tf.keras.utils.to_categorical(df['label_enc'].values)\n",
        "X_train, X_temp, y_train, y_temp = safe_train_test_split(X, y, test_size=0.30, random_state=RANDOM_STATE, stratify_labels=df['label_enc'])\n",
        "X_val, X_test, y_val, y_test = safe_train_test_split(X_temp, y_temp, test_size=0.5, random_state=RANDOM_STATE, stratify_labels=np.argmax(y_temp, axis=1))\n",
        "\n",
        "print(f\"Split -> Train: {len(X_train)} | Val: {len(X_val)} | Test: {len(X_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFHz4oybtGQ5",
        "outputId": "c2347582-3550-4135-df8b-907b400ff0d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Loaded 2000 lines.\n",
            "Cleaning content...\n",
            "Encoding labels...\n",
            "Label mapping: {0: 'ERROR', 1: 'FATAL', 2: 'INFO', 3: 'WARN'}\n",
            "Warning: Stratified split failed due to minority class(es). Falling back to non-stratified split for this step.\n",
            "Split -> Train: 1400 | Val: 300 | Test: 300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer\n",
        "print(\"Fitting tokenizer...\")\n",
        "tokenizer = Tokenizer(num_words=MAX_VOCAB, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = min(MAX_VOCAB, len(word_index) + 1)\n",
        "print(\"Vocab size:\", vocab_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmvLFS2GtN2H",
        "outputId": "e268e997-2944-442f-f8d7-726361181d11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting tokenizer...\n",
            "Vocab size: 317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sequences\n",
        "def texts_to_padded_sequences(texts):\n",
        "    seq = tokenizer.texts_to_sequences(texts)\n",
        "    return pad_sequences(seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
        "\n",
        "X_train_seq = texts_to_padded_sequences(X_train)\n",
        "X_val_seq = texts_to_padded_sequences(X_val)\n",
        "X_test_seq = texts_to_padded_sequences(X_test)\n"
      ],
      "metadata": {
        "id": "BM598O1Ptuf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model\n",
        "# ---------------------------\n",
        "print(\"Building model...\")\n",
        "num_classes = y.shape[1]\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=EMBEDDING_DIM, input_length=MAX_LEN),\n",
        "    Bidirectional(LSTM(128, return_sequences=False)),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "qSW7t76kuBu6",
        "outputId": "6a037f76-c6cc-409f-a026-0c15abad2d15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# callbacks & path\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "checkpoint = ModelCheckpoint(MODEL_PATH, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "early = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True, mode='max')\n",
        "\n",
        "# class weights (si déséquilibre)\n",
        "# calcul à partir des labels d'entraînement\n",
        "y_integers = np.argmax(y_train, axis=1)\n",
        "classes, counts = np.unique(y_integers, return_counts=True)\n",
        "class_weight = {}\n",
        "for cls, cnt in zip(classes, counts):\n",
        "    class_weight[cls] = (len(y_integers) / (len(classes) * cnt))\n",
        "print(\"Class weights:\", class_weight)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cPachqmuIL8",
        "outputId": "c588460f-e171-4e92-8c85-2e2b78fb41bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights: {np.int64(0): np.float64(3.3333333333333335), np.int64(1): np.float64(350.0), np.int64(2): np.float64(0.4807692307692308), np.int64(3): np.float64(0.6183745583038869)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "# ---------------------------\n",
        "print(\"Training...\")\n",
        "history = model.fit(\n",
        "    X_train_seq, y_train,\n",
        "    validation_data=(X_val_seq, y_val),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[checkpoint, early],\n",
        "    class_weight=class_weight,\n",
        "    verbose=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qy-6A2KzuPdy",
        "outputId": "ac7c0e2e-7f76-4d78-bdec-802b1c2f6b5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training...\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.81333, saving model to saved_model/lstm_Hadoop.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22/22 - 19s - 878ms/step - accuracy: 0.5786 - loss: 1.5153 - val_accuracy: 0.8133 - val_loss: 0.5430\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.81333 to 0.96333, saving model to saved_model/lstm_Hadoop.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22/22 - 18s - 802ms/step - accuracy: 0.9214 - loss: 0.5611 - val_accuracy: 0.9633 - val_loss: 0.1276\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.96333 to 0.97333, saving model to saved_model/lstm_Hadoop.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22/22 - 20s - 929ms/step - accuracy: 0.9850 - loss: 0.3261 - val_accuracy: 0.9733 - val_loss: 0.0925\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.97333 to 0.98667, saving model to saved_model/lstm_Hadoop.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22/22 - 20s - 915ms/step - accuracy: 0.9764 - loss: 0.3177 - val_accuracy: 0.9867 - val_loss: 0.0312\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.98667\n",
            "22/22 - 11s - 495ms/step - accuracy: 0.9943 - loss: 0.1308 - val_accuracy: 0.9833 - val_loss: 0.0929\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.98667\n",
            "22/22 - 12s - 526ms/step - accuracy: 0.9957 - loss: 0.1704 - val_accuracy: 0.9800 - val_loss: 0.0997\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.98667\n",
            "22/22 - 21s - 968ms/step - accuracy: 0.9950 - loss: 0.0214 - val_accuracy: 0.9833 - val_loss: 0.0688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save tokenizer & label map\n",
        "with open(TOKENIZER_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(tokenizer.to_json())\n",
        "with open(os.path.join(MODEL_DIR, \"label_map.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(label_map, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"Model and tokenizer saved to\", MODEL_DIR)\n",
        "\n",
        "# ---------------------------\n",
        "# Evaluation\n",
        "# ---------------------------\n",
        "print(\"Loading best model for evaluation...\")\n",
        "best_model = load_model(MODEL_PATH)\n",
        "\n",
        "y_pred_prob = best_model.predict(X_test_seq)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"Classification report:\")\n",
        "# Get unique labels present in y_true\n",
        "unique_y_true_labels = np.unique(y_true)\n",
        "# Filter target_names to match only the present labels\n",
        "target_names_for_report = [le.classes_[i] for i in unique_y_true_labels]\n",
        "print(classification_report(y_true, y_pred, labels=unique_y_true_labels, target_names=target_names_for_report))\n",
        "\n",
        "print(\"Confusion matrix:\")\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(cm)\n",
        "\n",
        "# Optionnel : sauvegarder résultats\n",
        "res_df = pd.DataFrame({\n",
        "    \"text\": X_test,\n",
        "    \"true\": [le.classes_[i] for i in y_true],\n",
        "    \"pred\": [le.classes_[i] for i in y_pred],\n",
        "    \"pred_prob\": [float(np.max(p)) for p in y_pred_prob]\n",
        "})\n",
        "res_df.to_csv(os.path.join(MODEL_DIR, \"test_predictions.csv\"), index=False)\n",
        "print(\"Predictions saved:\", os.path.join(MODEL_DIR, \"test_predictions.csv\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSCDmPDFujps",
        "outputId": "e4a25f92-a69b-4c38-8536-c1b4c824ceeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer saved to saved_model\n",
            "Loading best model for evaluation...\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 124ms/step\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       ERROR       1.00      0.94      0.97        17\n",
            "        INFO       0.99      0.99      0.99       161\n",
            "        WARN       0.99      1.00      1.00       122\n",
            "\n",
            "    accuracy                           0.99       300\n",
            "   macro avg       1.00      0.98      0.99       300\n",
            "weighted avg       0.99      0.99      0.99       300\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 16   1   0]\n",
            " [  0 160   1]\n",
            " [  0   0 122]]\n",
            "Predictions saved: saved_model/test_predictions.csv\n"
          ]
        }
      ]
    }
  ]
}